{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ea8v7ccqMGAu"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "\n",
        "\n",
        "# Load datasets (update path if using Google Drive)\n",
        "daily_df = pd.read_csv(\"/content/gwl-daily.csv\")\n",
        "monthly_df = pd.read_csv(\"/content/gwl-monthly.csv\")\n",
        "stations_df = pd.read_csv(\"/content/gwl-stations.csv\")\n",
        "\n",
        "# Display basic info\n",
        "print(\"Daily Groundwater Data:\", daily_df.shape)\n",
        "print(\"Monthly Groundwater Data:\", monthly_df.shape)\n",
        "print(\"Station Data:\", stations_df.shape)\n",
        "\n",
        "# Convert date column to datetime format\n",
        "daily_df[\"MSMT_DATE\"] = pd.to_datetime(daily_df[\"MSMT_DATE\"])\n",
        "monthly_df[\"MSMT_DATE\"] = pd.to_datetime(monthly_df[\"MSMT_DATE\"])\n",
        "\n",
        "# Select relevant columns for prediction\n",
        "columns_needed = [\"MSMT_DATE\", \"STATION\", \"WSE\"]\n",
        "daily_data = daily_df[columns_needed].dropna()\n",
        "\n",
        "# Sort values by station and date\n",
        "daily_data = daily_data.sort_values(by=[\"STATION\", \"MSMT_DATE\"])\n",
        "\n",
        "# Create lag features (Time-Series Features)\n",
        "def create_lagged_features(df, station_id, lags=10):\n",
        "    station_data = df[df[\"STATION\"] == station_id].copy()\n",
        "    for lag in range(1, lags + 1):\n",
        "        station_data[f\"WSE_lag{lag}\"] = station_data[\"WSE\"].shift(lag)\n",
        "    return station_data.dropna()\n",
        "\n",
        "# Select a sample station for modeling\n",
        "sample_station = daily_data[\"STATION\"].value_counts().idxmax()\n",
        "station_data = create_lagged_features(daily_data, sample_station)\n",
        "\n",
        "# Prepare dataset for training\n",
        "features = [col for col in station_data.columns if \"lag\" in col]\n",
        "X = station_data[features]\n",
        "y = station_data[\"WSE\"]\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "# Scale data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "### Traditional Machine Learning Models ###\n",
        "\n",
        "# 1. Random Forest Regressor\n",
        "rf_model = RandomForestRegressor(n_estimators=100)\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test_scaled)\n",
        "rf_mse = mean_squared_error(y_test, y_pred_rf)\n",
        "rf_r2 = r2_score(y_test, y_pred_rf)\n",
        "\n",
        "# 2. Support Vector Machine Regressor\n",
        "svm_model = SVR()\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "y_pred_svm = svm_model.predict(X_test_scaled)\n",
        "svm_mse = mean_squared_error(y_test, y_pred_svm)\n",
        "svm_r2 = r2_score(y_test, y_pred_svm)\n",
        "\n",
        "### Deep Learning Model: RNN (LSTM) ###\n",
        "X_train_rnn = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_rnn = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build LSTM Model\n",
        "lstm_model = Sequential([\n",
        "    LSTM(50, activation='relu', input_shape=(X_train_rnn.shape[1], 1)),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "lstm_model.compile(optimizer='adam', loss='mse')\n",
        "lstm_model.fit(X_train_rnn, y_train, epochs=20, verbose=0)\n",
        "\n",
        "# Make LSTM predictions\n",
        "y_pred_lstm = lstm_model.predict(X_test_rnn).flatten()\n",
        "lstm_mse = mean_squared_error(y_test, y_pred_lstm)\n",
        "lstm_r2 = r2_score(y_test, y_pred_lstm)\n",
        "\n",
        "# Compare Model Performance\n",
        "results = pd.DataFrame({\n",
        "    \"Model\": [\"Random Forest\", \"SVM\", \"LSTM\"],\n",
        "    \"MSE\": [rf_mse, svm_mse, lstm_mse],\n",
        "    \"R2 Score\": [rf_r2, svm_r2, lstm_r2]\n",
        "})\n",
        "print(\"\\nModel Comparison:\\n\", results)\n",
        "\n",
        "# Plot Predictions\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(y_test.values, label=\"Actual\", linestyle=\"dashed\")\n",
        "plt.plot(y_pred_rf, label=\"Random Forest Prediction\")\n",
        "plt.plot(y_pred_svm, label=\"SVM Prediction\")\n",
        "plt.plot(y_pred_lstm, label=\"LSTM Prediction\")\n",
        "plt.legend()\n",
        "plt.title(\"Groundwater Level Predictions: ML vs LSTM\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Improved LSTM Model\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "# Reshape input for LSTM\n",
        "X_train_rnn = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_rnn = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the enhanced LSTM model\n",
        "lstm_model = Sequential([\n",
        "    LSTM(128, activation='relu', return_sequences=True, input_shape=(X_train_rnn.shape[1], 1)),  # First LSTM layer\n",
        "    Dropout(0.2),  # Dropout to prevent overfitting\n",
        "    LSTM(128, activation='relu', return_sequences=True),  # Second LSTM layer\n",
        "    Dropout(0.2),\n",
        "    LSTM(128, activation='relu'),  # Third LSTM layer\n",
        "    Dropout(0.2),\n",
        "    Dense(1)  # Output layer\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "lstm_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
        "\n",
        "# Train LSTM model with more epochs\n",
        "lstm_model.fit(X_train_rnn, y_train, epochs=50, batch_size=32, verbose=1)\n",
        "\n",
        "# Make Predictions\n",
        "y_pred_lstm = lstm_model.predict(X_test_rnn).flatten()\n",
        "\n",
        "# Evaluate Performance\n",
        "lstm_mse = mean_squared_error(y_test, y_pred_lstm)\n",
        "lstm_r2 = r2_score(y_test, y_pred_lstm)\n",
        "\n",
        "print(f\"\\nEnhanced LSTM Model: MSE = {lstm_mse:.5f}, RÂ² = {lstm_r2:.5f}\")\n",
        "\n",
        "# Compare Model Performance\n",
        "results = pd.DataFrame({\n",
        "    \"Model\": [\"Random Forest\", \"SVM\", \"Enhanced LSTM\"],\n",
        "    \"MSE\": [rf_mse, svm_mse, lstm_mse],\n",
        "    \"R2 Score\": [rf_r2, svm_r2, lstm_r2]\n",
        "})\n",
        "print(\"\\nUpdated Model Comparison:\\n\", results)\n",
        "\n",
        "# Plot Predictions\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(y_test.values, label=\"Actual\", linestyle=\"dashed\", color='black')\n",
        "plt.plot(y_pred_rf, label=\"Random Forest Prediction\", color='blue')\n",
        "plt.plot(y_pred_svm, label=\"SVM Prediction\", color='red')\n",
        "plt.plot(y_pred_lstm, label=\"Enhanced LSTM Prediction\", color='green')\n",
        "plt.legend()\n",
        "plt.title(\"Improved Groundwater Level Predictions: ML vs Enhanced LSTM\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "myvaK07HQvq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout\n",
        "\n",
        "# Load datasets\n",
        "daily_df = pd.read_csv(\"/content/gwl-daily.csv\")\n",
        "monthly_df = pd.read_csv(\"/content/gwl-monthly.csv\")\n",
        "stations_df = pd.read_csv(\"/content/gwl-stations.csv\")\n",
        "\n",
        "# Convert date column to datetime format\n",
        "daily_df[\"MSMT_DATE\"] = pd.to_datetime(daily_df[\"MSMT_DATE\"])\n",
        "monthly_df[\"MSMT_DATE\"] = pd.to_datetime(monthly_df[\"MSMT_DATE\"])\n",
        "\n",
        "# Select relevant columns for prediction\n",
        "columns_needed = [\"MSMT_DATE\", \"STATION\", \"WSE\"]\n",
        "daily_data = daily_df[columns_needed].dropna()\n",
        "\n",
        "daily_data = daily_data.sort_values(by=[\"STATION\", \"MSMT_DATE\"])\n",
        "\n",
        "def create_lagged_features(df, station_id, lags=10):\n",
        "    station_data = df[df[\"STATION\"] == station_id].copy()\n",
        "    for lag in range(1, lags + 1):\n",
        "        station_data[f\"WSE_lag{lag}\"] = station_data[\"WSE\"].shift(lag)\n",
        "    return station_data.dropna()\n",
        "\n",
        "sample_station = daily_data[\"STATION\"].value_counts().idxmax()\n",
        "station_data = create_lagged_features(daily_data, sample_station)\n",
        "\n",
        "features = [col for col in station_data.columns if \"lag\" in col]\n",
        "X = station_data[features]\n",
        "y = station_data[\"WSE\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Traditional Machine Learning Models\n",
        "rf_model = RandomForestRegressor(n_estimators=100)\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test_scaled)\n",
        "\n",
        "svm_model = SVR()\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "y_pred_svm = svm_model.predict(X_test_scaled)\n",
        "\n",
        "X_train_rnn = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_rnn = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Hybrid Model: Bidirectional LSTM + Random Forest\n",
        "lstm_model = Sequential([\n",
        "    Bidirectional(LSTM(128, return_sequences=True, activation='relu'), input_shape=(X_train_rnn.shape[1], 1)),\n",
        "    Dropout(0.2),\n",
        "    Bidirectional(LSTM(64, return_sequences=True, activation='relu')),\n",
        "    Dropout(0.2),\n",
        "    Bidirectional(LSTM(32, activation='relu')),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "lstm_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
        "lstm_model.fit(X_train_rnn, y_train, epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "y_pred_lstm = lstm_model.predict(X_test_rnn).flatten()\n",
        "\n",
        "# Hybrid Model Combining Predictions\n",
        "hybrid_pred = (y_pred_lstm + y_pred_rf) / 2\n",
        "\n",
        "# Performance Evaluation\n",
        "rf_mse = mean_squared_error(y_test, y_pred_rf)\n",
        "rf_r2 = r2_score(y_test, y_pred_rf)\n",
        "svm_mse = mean_squared_error(y_test, y_pred_svm)\n",
        "svm_r2 = r2_score(y_test, y_pred_svm)\n",
        "lstm_mse = mean_squared_error(y_test, y_pred_lstm)\n",
        "lstm_r2 = r2_score(y_test, y_pred_lstm)\n",
        "hybrid_mse = mean_squared_error(y_test, hybrid_pred)\n",
        "hybrid_r2 = r2_score(y_test, hybrid_pred)\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    \"Model\": [\"Random Forest\", \"SVM\", \"Bidirectional LSTM\", \"Hybrid Model\"],\n",
        "    \"MSE\": [rf_mse, svm_mse, lstm_mse, hybrid_mse],\n",
        "    \"R2 Score\": [rf_r2, svm_r2, lstm_r2, hybrid_r2]\n",
        "})\n",
        "print(\"\\nModel Comparison:\\n\", results)\n",
        "\n",
        "# Plot Predictions\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(y_test.values, label=\"Actual\", linestyle=\"dashed\")\n",
        "plt.plot(y_pred_rf, label=\"Random Forest Prediction\")\n",
        "plt.plot(y_pred_svm, label=\"SVM Prediction\")\n",
        "plt.plot(y_pred_lstm, label=\"Bidirectional LSTM Prediction\")\n",
        "plt.plot(hybrid_pred, label=\"Hybrid Model Prediction\", linestyle=\"dotted\")\n",
        "plt.legend()\n",
        "plt.title(\"Groundwater Level Predictions: ML vs LSTM vs Hybrid\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1cfe3aLATRIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-CfOuIAUMIxz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}